# CompoLens ðŸŽ¯ðŸ“·  
_A Saliency-Based Composition Assistant for Photographers_

**CompoLens** is an AI-powered tool that simulates human visual attention to help photographers assess and improve their image composition. Built for Georgia Techâ€™s **CSâ€¯6795: Cognitive Science** course, it explores how computational models of saliency can be used to mimic aesthetic decision-making in photography.

---

## ðŸ§  Project Goal

Humans tend to focus on specific regions of an image based on visual saliency â€” features like contrast, brightness, and structure. CompoLens uses state-of-the-art **saliency prediction models** to:
- Highlight the focal areas of a photograph
- Evaluate how well the intended subject stands out
- Provide real-time feedback to improve framing and balance

---

## ðŸ”§ Features

- ðŸ–¼ï¸ Upload any photo for analysis  
- ðŸ§  Predict saliency maps using AI models (e.g. DeepGaze, SAM, etc.)  
- ðŸŽ¯ Click to indicate your intended focal point  
- âœ… Get visual + textual feedback on how well your subject aligns with predicted human attention  
- ðŸ’¡ Built with `Streamlit` for rapid visual prototyping

---

## ðŸ› ï¸ Tech Stack

- Python, Streamlit
- Torch/ONNX (planned support for neural saliency models)
- OpenCV for image processing
- PIL for image manipulation

---

## ðŸ“Œ Example Use Cases

- Fine-tuning portrait and product composition  
- Training aid for photography students and hobbyists  
- Creative tool for analyzing balance and framing

---

## ðŸ Next Steps

- Add more saliency models (DeepGaze, SAM integration)
- Enable drag-and-drop image uploading
- Build batch analysis for contact sheets
- Export annotated images for photographer feedback loops


---

## ðŸ“¸ Sample Screenshot

> _Coming soon!_ (Add a screenshot or GIF to show the interface in action)
