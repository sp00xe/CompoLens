# CompoLens 🎯📷  
_A Saliency-Based Composition Assistant for Photographers_

**CompoLens** is an AI-powered tool that simulates human visual attention to help photographers assess and improve their image composition. Built for Georgia Tech’s **CS 6795: Cognitive Science** course, it explores how computational models of saliency can be used to mimic aesthetic decision-making in photography.

---

## 🧠 Project Goal

Humans tend to focus on specific regions of an image based on visual saliency — features like contrast, brightness, and structure. CompoLens uses state-of-the-art **saliency prediction models** to:
- Highlight the focal areas of a photograph
- Evaluate how well the intended subject stands out
- Provide real-time feedback to improve framing and balance

---

## 🔧 Features

- 🖼️ Upload any photo for analysis  
- 🧠 Predict saliency maps using AI models (e.g. DeepGaze, SAM, etc.)  
- 🎯 Click to indicate your intended focal point  
- ✅ Get visual + textual feedback on how well your subject aligns with predicted human attention  
- 💡 Built with `Streamlit` for rapid visual prototyping

---

## 🛠️ Tech Stack

- Python, Streamlit
- Torch/ONNX (planned support for neural saliency models)
- OpenCV for image processing
- PIL for image manipulation

---

## 📌 Example Use Cases

- Fine-tuning portrait and product composition  
- Training aid for photography students and hobbyists  
- Creative tool for analyzing balance and framing

---

## 🏁 Next Steps

- Add more saliency models (DeepGaze, SAM integration)
- Enable drag-and-drop image uploading
- Build batch analysis for contact sheets
- Export annotated images for photographer feedback loops


---

## 📸 Sample Screenshot

> _Coming soon!_ (Add a screenshot or GIF to show the interface in action)
